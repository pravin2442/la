import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

iris = load_iris(as_frame=True)
X = iris.data
y = iris.target
feature_names = iris.feature_names
class_names = iris.target_names

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

clf = DecisionTreeClassifier(criterion="gini", max_depth=3, random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Test accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=class_names))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

sample = X_test.head(5).copy()
sample_pred = clf.predict(sample)
sample_display = sample.copy()
sample_display["Actual"] = [class_names[i] for i in y_test.iloc[:5]]
sample_display["Predicted"] = [class_names[i] for i in sample_pred]
print("\nSample Predictions (first 5 test rows):\n", sample_display)

plt.figure(figsize=(12, 8))
plot_tree(clf, feature_names=feature_names, class_names=class_names, filled=True, rounded=True, proportion=True, impurity=True)
plt.title("CART Decision Tree (Gini, max_depth=3)")
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
importances = clf.feature_importances_
indices = np.argsort(importances)
plt.barh(range(len(importances)), importances[indices])
plt.yticks(range(len(importances)), np.array(feature_names)[indices])
plt.xlabel("Feature importance")
plt.title("Feature Importances (CART)")
plt.tight_layout()
plt.show()
